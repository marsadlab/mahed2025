<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MAHED 2025 - Multimodal Detection of Hope and Hate Emotions in Arabic Content</title>
    <link rel="stylesheet" href="styles.css" />
</head>
<body>
    <header>
        <img src="mahed_logo.png" alt="MAHED 2025 Logo">
        <h1>MAHED 2025: Multimodal Detection of Hope and Hate Emotions in Arabic Content</h1>
    </header>

    <nav>
        <ul>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#data">Data</a></li>
            <li><a href="#tasks">Task Description</a></li>
            <li><a href="#pilot">Pilot Run</a></li>
            <li><a href="#timeline">Timeline</a></li>
            <li><a href="#organizers">Organizers</a></li>
        </ul>
    </nav>

    <div class="container">
        <section id="overview">
            <h2>Overview</h2>
            <p><strong>MAHED 2025 </strong> is a shared task at ArabicNLP 2025, focusing on the detection of <strong>hate speech, hope speech, and emotional expression </strong> in Arabic content across both <strong> textual</strong> and <strong> multimodal</strong> formats. This task aims to advance Arabic Natural Language Processing (NLP) through multi-task model and multimodal analysis. Participants may choose to participate in one or more of the following three subtasks:</p>
            <ul>
                <li><strong>Text-based Hate and Hope Speech Classification</strong></li>
                <li><strong>Emotion, Offensive, and Directed Hate Detection (Multitask)</strong></li>
                <li><strong>Multimodal Hateful Meme Detection</strong></li>
            </ul>

            <h3>Motivation</h3>
            <p>Social media in the Arabic-speaking world exhibits a dynamic interplay between hateful and hopeful expressions. However, challenges like linguistic diversity, dialect variation, limited datasets, and the emergence of multimodal content (e.g., memes) make automatic detection complex.</p>
            <p>MAHED 2025 addresses this by:</p>
            <ul>
                <li>Tackling the dual nature of content (hate vs. hope)</li>
                <li>Enabling multimodal (text + image) analysis</li>
                <li>Integrating emotion as a critical contextual feature</li>
                <li>Providing high-quality Arabic datasets for hate, hope, and emotion detection</li>
            </ul>
        </section>



        <section id="data">
            <h2>Dataset Resources</h2>
            <p>The shared task will use the following annotated datasets:</p>
            
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Attribute</th>
                        <th>Subtask 1</th>
                        <th>Subtask 2</th>
                        <th>Subtask 3</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Size</strong></td>
                        <td>10,000</td>
                        <td>15,000</td>
                        <td>4,060</td>
                    </tr>
                    <tr>
                        <td><strong>Labels</strong></td>
                        <td>
                            <ul>
                                <li>hope</li>
                                <li>hate</li>
                                <li>not_applicable</li>
                            </ul>
                        </td>
                        <td>
                            <ul>
                                <li>Emotion</li>
                                <li>Offensive</li>
                                <li>Hate</li>
                            </ul>
                        </td>
                        <td>
                            <ul>
                                <li>Hateful</li>
                                <li>Not-hateful</li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Source</strong></td>
                        <td>Rafiul et al. 2025</td>
                        <td>Wajdi et al.,2024</td>
                        <td>Firoj et. al,2024</td>
                    </tr>
                </tbody>
            </table>
            
            <div class="dataset-info">
                <p><strong>Annotation</strong>: All content was collected from public social media, anonymized, and annotated by native speakers. Annotation agreement (Cohen's Kappa) is > 0.75.</p>
                <p><strong>Data Split</strong>: Training, development, and test sets will be provided with evaluation scripts.</p>
                <p><strong>Ethics</strong>: The dataset complies with ethical data-sharing standards.</p>
            </div>
            
        </section>

        <section id="tasks">
            <h2>Task Description</h2>
            <p>MAHED 2025 consists of three interconnected subtasks:</p>
            
            <div class="subtask">
                <h4>Sub-task 1: Text-based Hate and Hope Speech Classification</h4>
                <p><strong>Goal:</strong> Classify Arabic text as hate, hope, or not_applicable</p>
                <ul>  
                    <li><strong>Input:</strong> Arabic text (MSA or dialect)</li>
                    <li><strong>Output:</strong> Labels—'hate', 'hope', or 'not_applicable'</li>
                </ul>                    
                <p><strong>Examples:</strong></p>
                <div class="examples-container">
                    <ul class="example-list">
                        <li>
                            <div class="example-row">
                                <div class="arabic-text">كل المهاجرين لصوص ومجرمون يجب طردهم فوراً</div>
                                <div class="example-label"><strong>Label:</strong> hate</div>
                            </div>
                        </li>
                        <li>
                            <div class="example-row">
                                <div class="arabic-text">معاً يمكننا بناء مستقبل أفضل لأطفالنا</div>
                                <div class="example-label"><strong>Label:</strong> hope</div>
                            </div>
                        </li>
                        <li>
                            <div class="example-row">
                                <div class="arabic-text">اليوم هو يوم مشمس وجميل</div>
                                <div class="example-label"><strong>Label:</strong> not_applicable</div>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
                        
        <div class="subtask">
                <h4>Sub-task 2: Emotion, Offensive Language, and Directed Hate Detection</h4>
                <p><strong>Goal</strong>: Identify the <strong>emotion</strong>, whether the text is <strong>offensive</strong>, and if offensive, whether it contains <strong>identity-targeted hate (directed hate)</strong>.</p>
                            
                    <div class="labels-section">
                        <div class="emoji-header">
                        <h3>Labels</h3>
                    </div>
                    <ul>
                        <li><strong>Emotion</strong> (single label): neutral, anger, anticipation, disgust, fear, joy, love, optimism, pessimism, sadness, surprise, trust</li>
                        <li><strong>Offensive</strong>: yes, no</li>
                        <li><strong>Directed Hate</strong> (if offensive = yes): yes-directed (identity-targeted hate) no-directed (non-targeted or casual offensiveness)</li>
                    </ul>
                </div>
        
        <div class="distinctions-section">
            <div class="emoji-header">
                <h3>Key Distinctions</h3>
            </div>
            <ul class="distinctions-list">
                <li><strong>Hate speech is always offensive</strong>, but not all offensive content is hate speech.</li>
                <li><strong>Directed hate</strong> refers to offensive content targeting a group/person based on identity (e.g., race, gender, religion).</li>
            </ul>
        </div>
        
        <table class="examples-table">
            <thead>
                <tr>
                    <th>Text</th>
                    <th>Emotion</th>
                    <th>Offensive</th>
                    <th>Directed Hate</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>
                        <span class="arabic-text">كل المهاجرين لصوص ويجب طردهم</span>
                    </td>
                    <td>anger</td>
                    <td>yes</td>
                    <td class="yes-directed">yes-directed</td>
                </tr>
                <tr>
                    <td>
                        <span class="arabic-text">يا حمار ليش نسيت المفاتيح؟</span>
                    </td>
                    <td>anger</td>
                    <td>yes</td>
                    <td class="no-directed">no-directed</td>
                </tr>
                <tr>
                    <td>
                        <span class="arabic-text">الحكومة فاشلة وما تسوى شي مفيد</span>
                    </td>
                    <td>anger</td>
                    <td>yes</td>
                    <td class="yes-directed">yes-directed</td>
                </tr>
                <tr>
                    <td>
                        <span class="arabic-text">تكفون بيجيبون لي امراض مابي اشوف احد</span>
                    </td>
                    <td>fear</td>
                    <td class="no-offensive">no</td>
                    <td class="dash">—</td>
                </tr>
                <tr>
                    <td>
                        <span class="arabic-text">أشعر بالحزن لأنني خسرت وظيفتي</span>
                    </td>
                    <td>sadness</td>
                    <td class="no-offensive">no</td>
                    <td class="dash">—</td>
                </tr>
            </tbody>
        </table>
        </div>



            <div class="subtask">
                <h4>Sub-task 3: Multimodal Hateful Meme Detection</h4>
                <ul>
                    <li><strong>Input:</strong> Image + text pairs (Arabic memes).</li>
                    <li><strong>Output:</strong> Binary label (‘hateful’ and ‘non-hateful’).</li>
                    <li><strong>Goal:</strong> Detect hate in multimodal content.</li>
                    <li><strong>Examples:</strong>
                        <ul>
                            <li>Hateful: Text: <span class="arabic-text">"الشعب ده ما يستاهلش غير كده"</span> (This people don’t deserve anything but this.) + Image: Cartoon mocking a group - Hate</li>
                            <li>Non-hateful: Text: <span class="arabic-text">"لما تصحى الصبح وتالقي القهوة جاهزة"</span> (When you wake up and find the coffee ready.) + Image: Cheerful person with coffee - Non-hate</li>
                        </ul>
                    </li>
                </ul>
            </div>
            <p>Participants may engage in any or all sub-tasks. The evaluation uses F1-score, precision, and recall, with macro-averaged F1 as the primary metric.</p>
        </section>

        <section id="pilot">
                <h2>Evaluation Metrics</h2>
                <div class="metrics-container">
                    <p>Evaluation will be performed using:</p>
                    <ul class="metrics-list">
                        <li>
                            <div class="primary-metric">
                                <strong>Macro-averaged F1-score</strong>
                                <span class="metric-note">*(primary metric)*</span>
                            </div>
                        </li>
                        <li><strong>Precision and Recall</strong></li>
                        <li><strong>Separate leaderboards per sub-task</strong></li>
                    </ul>
                </div>

            <h2>Pilot Run Details</h2>
            <p>A pilot study with 2,000 text instances and 500 memes yielded:</p>
            <ul>
                <li>Sub-task 1: F1 0.71 (hate), 0.82 (hope) with BERT</li>
                <li>Sub-task 2: F1 0.51 with CLIP-style model</li>
                <li>Sub-task 3: F1 0.68 for multimodal hate memes</li>
            </ul>
            <p>Feedback refined the dataset; details will be shared upon acceptance.</p>
        </section>

        <section id="timeline">
            <h2>Timeline</h2>
            <table class="comparison-table">
                <tr>
                    <th>Date</th>
                    <th>Event</th>
                </tr>
                <tr>
                    <td>June 1, 2025</td>
                    <td>Release of training, dev data and evaluation scripts</td>
                </tr>
                <tr>
                    <td>July 20, 2025</td>
                    <td>Final registration deadline and test set release</td>
                </tr>
                <tr>
                    <td>July 25, 2025</td>
                    <td>Test submission deadline via CodaLab</td>
                </tr>
                <tr>
                    <td>July 30, 2025</td>
                    <td>Final results released to participants</td>
                </tr>
                <tr>
                    <td>August 15, 2025</td>
                    <td>System description papers due</td>
                </tr>
                <tr>
                    <td>November 5-9, 2025</td>
                    <td>ArabicNLP 2025 Workshop in Suzhou, China</td>
                </tr>
            </table>
        </section>

        <section id="organizers">
            <h2>Organizing Team</h2>
            <ul>
                <li>Wajdi Zaghouani, Northwestern University in Qatar (<a href="mailto:wajdi.zaghouani@northwestern.edu">wajdi.zaghouani@northwestern.edu</a>)</li>
                <li>Md. Rafiul Biswas, Hamad Bin Khalifa University, Doha, Qatar (<a href="mailto:mbiswas@hbku.edu.qa">mbiswas@hbku.edu.qa</a>)</li>
                <li>Mabrouka Bessghaier, Northwestern University in Qatar (<a href="mailto:mabrouka.bessghaier@northwestern.edu">mabrouka.bessghaier@northwestern.edu</a>)</li>
                <li>Shimaa Ibrahim, Northwestern University in Qatar (<a href="mailto:shimaa.ibrahim@northwestern.edu">shimaa.ibrahim@northwestern.edu</a>)</li>
                <li>Firoj Alam, Qatar Computing Research Institute, HBKU (<a href="mailto:fialam@hbku.edu.qa">fialam@hbku.edu.qa</a>)</li>
            </ul>
            <p><strong>Reference:</strong><br></p>
            
            <p>Biswas, Md. Rafiul and Wajdi Zaghouani. 2025. EmoHopeSpeech: An Annotated Dataset of Emotions and Hope Speech in English and Arabic. arXiv preprint  arXiv:2505.11959 [cs.CL]</p>

            <p>Zaghouani, Wajdi, Hamdy Mubarak, and Md. Rafiul Biswas. 2024. So Hateful! Building a Multi-Label Hate Speech Annotated Arabic Dataset. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024), pages 15044–15055, Torino, Italy</p>

            <p>Alam, Firoj, et al. "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-agent LLMs." International Conference on Web Information Systems Engineering. Singapore: Springer Nature Singapore, 2024.</p>



        </section>
    </div>

    <footer>
        <p>&copy; 2025 MAHED Shared Task. All rights reserved.</p>
    </footer>
</body>
</html>